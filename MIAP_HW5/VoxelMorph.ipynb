{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Please finish the sections of the notebook labeled 'To Do.'"
      ],
      "metadata": {
        "id": "ZiMRQoyO7S-i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mqIepb07Kd8"
      },
      "outputs": [],
      "source": [
        "# install voxelmorph, which will also install dependencies: neurite and pystrum\n",
        "!pip install voxelmorph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import os, sys\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
        "import voxelmorph as vxm\n",
        "import neurite as ne"
      ],
      "metadata": {
        "id": "8QQjYXTz72gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download MRI tutorial data\n",
        "!wget https://surfer.nmr.mgh.harvard.edu/pub/data/voxelmorph/tutorial_data.tar.gz -O data.tar.gz\n",
        "!tar -xzvf data.tar.gz"
      ],
      "metadata": {
        "id": "MwNY4ei78Uqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "npz = np.load('tutorial_data.npz')\n",
        "x_train = npz['train']\n",
        "x_val = npz['validate']\n",
        "\n",
        "# the 208 volumes are of size 160x192\n",
        "vol_shape = x_train.shape[1:]\n",
        "print('train shape:', x_train.shape)\n"
      ],
      "metadata": {
        "id": "jppog8jW8efx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### To Do: plot 5 random sample from train data\n",
        "nb_vis = 5\n",
        "idx = np.random.randint(0, x_train.shape[0], [5,])\n",
        "example_digits = [f for f in x_train[idx, ...]]\n",
        "\n",
        "# visualize\n",
        "ne.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);"
      ],
      "metadata": {
        "id": "oNsFhHK48mnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unet\n",
        "nb_features = [\n",
        "    [32, 32, 32, 32],         # encoder features\n",
        "    [32, 32, 32, 32, 32, 16]  # decoder features\n",
        "]\n",
        "vxm_model = vxm.networks.VxmDense(vol_shape, nb_features, int_steps=0)\n",
        "\n",
        "# losses and loss weights\n",
        "losses = ['mse', vxm.losses.Grad('l2').loss]\n",
        "loss_weights = [1, 0.01]\n"
      ],
      "metadata": {
        "id": "0LYwgUBE8zPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vxm_data_generator(x_data, batch_size=32):\n",
        "    \"\"\"\n",
        "    Generator that takes in data of size [N, H, W], and yields data for\n",
        "    our custom vxm model. Note that we need to provide numpy data for each\n",
        "    input, and each output.\n",
        "\n",
        "    inputs:  moving [bs, H, W, 1], fixed image [bs, H, W, 1]\n",
        "    outputs: moved image [bs, H, W, 1], zero-gradient [bs, H, W, 2]\n",
        "    \"\"\"\n",
        "\n",
        "    # preliminary sizing\n",
        "    vol_shape = x_data.shape[1:] # extract data shape\n",
        "    ndims = len(vol_shape)\n",
        "\n",
        "    # prepare a zero array the size of the deformation\n",
        "    # we'll explain this below\n",
        "    zero_phi = np.zeros([batch_size, *vol_shape, ndims])\n",
        "\n",
        "    while True:\n",
        "        # prepare inputs:\n",
        "        # images need to be of the size [batch_size, H, W, 1]\n",
        "        idx1 = np.random.randint(0, x_data.shape[0], size=batch_size)\n",
        "        moving_images = x_data[idx1, ..., np.newaxis]\n",
        "        idx2 = np.random.randint(0, x_data.shape[0], size=batch_size)\n",
        "        fixed_images = x_data[idx2, ..., np.newaxis]\n",
        "        inputs = [moving_images, fixed_images]\n",
        "\n",
        "        # prepare outputs (the 'true' moved image):\n",
        "        # of course, we don't have this, but we know we want to compare\n",
        "        # the resulting moved image with the fixed image.\n",
        "        # we also wish to penalize the deformation field.\n",
        "        outputs = [fixed_images, zero_phi]\n",
        "\n",
        "        yield (inputs, outputs)"
      ],
      "metadata": {
        "id": "PQR3Vpw_9n_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing train data generator\n",
        "train_generator = vxm_data_generator(x_train, batch_size=8)\n",
        "in_sample, out_sample = next(train_generator)\n",
        "\n"
      ],
      "metadata": {
        "id": "oVOTytVd-C7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vxm_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=losses, loss_weights=loss_weights)"
      ],
      "metadata": {
        "id": "JyGmZMa5-2uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = vxm_model.fit_generator(train_generator, epochs=5, steps_per_epoch=5, verbose=2);"
      ],
      "metadata": {
        "id": "xbQ5Rfnu-tHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(hist, loss_name='loss'):\n",
        "    # Simple function to plot training history.\n",
        "    plt.figure()\n",
        "    plt.plot(hist.epoch, hist.history[loss_name], '.-')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n",
        "\n",
        "plot_history(hist)"
      ],
      "metadata": {
        "id": "_WYTVFCx_bDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: train model for 100 more epoches"
      ],
      "metadata": {
        "id": "EIwKeK_e__a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the validation data generator\n",
        "val_generator = vxm_data_generator(x_val, batch_size = 1)\n",
        "val_input, _ = next(val_generator)"
      ],
      "metadata": {
        "id": "5OzsrwxOAC6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting output for validation data\n",
        "val_pred = vxm_model.predict(val_input)"
      ],
      "metadata": {
        "id": "vAXcNqbTAHQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize registration\n",
        "images = [img[0, :, :, 0] for img in val_input + val_pred]\n",
        "titles = ['moving', 'fixed', 'moved', 'flow']\n",
        "ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);"
      ],
      "metadata": {
        "id": "z5kR19suAMHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize flow\n",
        "flow = val_pred[1].squeeze()[::3,::3]\n",
        "ne.plot.flow([flow], width=5);"
      ],
      "metadata": {
        "id": "0oyebVliAPrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        " TO DO:\n",
        "\n",
        "Train two models with different loss weights:\n",
        "\n",
        "1. Model 1:\n",
        "   - Loss weights: [1, 0.00001]\n",
        "   - Train for 100 epochs\n",
        "\n",
        "2. Model 2:\n",
        "   - Loss weights: [1, 0.1]\n",
        "   - Train for 100 epochs\n",
        "\n",
        "After training, compare the results of each method to each other and analyze your findings.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VaRapOI5ARPX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}